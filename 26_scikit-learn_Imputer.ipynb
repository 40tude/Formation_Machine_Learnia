{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer - Nettoyage des données\n",
    "\n",
    "* Dans pandas il y a df.fillna()\n",
    "* Dans le module **impute** de sklearn\n",
    "* Ces transformers permettent de nettoyer le dataset en éliminant, remplacant des valeurs manquantes\n",
    "\n",
    "On va voir : \n",
    "* SimpleImputer\n",
    "* KNNImputer\n",
    "* MissingIndicator\n",
    "\n",
    "\n",
    "## SimpleImputer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.,  3.],\n",
       "       [ 0.,  4.],\n",
       "       [ 5.,  3.],\n",
       "       [ 5.,  3.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_train = np.array([[10,3],\n",
    "              [0,4],\n",
    "              [5,3],\n",
    "              [np.nan, 3]\n",
    "              ])\n",
    "# strategy = mean, median, most_frequent, constant\n",
    "imputer = SimpleImputer(missing_values = np.nan, \n",
    "                        strategy = \"mean\")\n",
    "imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La moyenne de la 1ere colonne remplace bien np.nan\n",
    "* On peut ensuite appliquer ce Transformer à d'autres dataset\n",
    "* X_test par exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous bien voir qu'on utilise transform() et pas fit_transform() car on veut appliquer les moyennes du Train set au Test set. \n",
    "\n",
    "De cette façon on est sûr de traiter toutes les données de la même façon qu'on a traité les données du Train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.  ,  5.  ],\n",
       "       [40.  ,  2.  ],\n",
       "       [ 5.  ,  5.  ],\n",
       "       [ 5.  ,  3.25]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[12, 5],\n",
    "              [40, 2],\n",
    "              [5, 5],\n",
    "              [np.nan, np.nan]\n",
    "              ])\n",
    "imputer.transform(X_test)          # transform()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourquoi on calcule pas les moyennes sur l'ensemble Train set + Test set et qu'on remplace les valeurs manquantes par ces moyennes?\n",
    "\n",
    "Si on fait ça il y a une \"fuite\" d'information du Test set vers le Train set. Certaines information issues du Test set sont utilisées pour entrainer le modèle. C'est pas du tout une bonne idée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNNImputer()\n",
    "\n",
    "* Depuis ver 0.22\n",
    "* Remplace les valeurs manquantes par celles des plus proches voisins\n",
    "\n",
    "![alt](assets/KNNImputer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 100.],\n",
       "       [200.,  21.],\n",
       "       [  3.,  15.],\n",
       "       [200.,  20.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "X = np.array([[1, 100],\n",
    "              [200, 21],\n",
    "              [3, 15],\n",
    "              [np.nan, 20]])\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Penser à utiliser GridSearchCV() afin de trouver le nombre optimal de voisins à passer à KNNIputer().\n",
    "* Voir plus bas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MissingIndicator()\n",
    "* Valeur booleene qui indique une valeur absente\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]]\n",
      "2\n",
      "Il y a 25.0% de données manquantes dans le dataset\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "X = np.array([[1, 100],\n",
    "              [2, 30],\n",
    "              [3, 15],\n",
    "              [np.nan, np.nan]])\n",
    "Indiq = MissingIndicator().fit_transform(X)\n",
    "print(Indiq)\n",
    "print(Indiq.sum()) # on peut déterminer \n",
    "print(f\"Il y a {100*Indiq.sum()/Indiq.size}% de données manquantes dans le dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On considère ici que les 2 dernières valeurs (classe, deck par exemple) sont celles d'un matelo. \n",
    "* Il n'a pas de class ni de pont\n",
    "* On va créer une nouvelle colonne pour distinguer les matelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 100.,   0.,   0.],\n",
       "       [  2.,  30.,   0.,   0.],\n",
       "       [  3.,  15.,   0.,   0.],\n",
       "       [-99., -99.,   1.,   1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.pipeline import make_union\n",
    "\n",
    "X = np.array([[1, 100],\n",
    "              [2, 30],\n",
    "              [3, 15],\n",
    "              [np.nan, np.nan]])\n",
    "MissingIndicator().fit_transform(X)\n",
    "pipeline = make_union (SimpleImputer(strategy=\"constant\", fill_value=-99), \n",
    "                       MissingIndicator())\n",
    "pipeline.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On retrouve les colonnes qui dans lesqeulles on a fait passer le SimpleIputer\n",
    "* make_union a aussi créé 2 colonnes qui permettent de savoir si c'est un passager ou un membre d'équipage\n",
    "\n",
    "### À noter\n",
    "On se sert du manque d'information (np.nan) pour créer une nouvelle information pour entrainer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "Utiliser GridSearchCV pour trouver les meilleurs paramètres du pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('knnimputer', KNNImputer()), ('sgdclassifier', SGDClassifier())],\n",
       " 'verbose': False,\n",
       " 'knnimputer': KNNImputer(),\n",
       " 'sgdclassifier': SGDClassifier(),\n",
       " 'knnimputer__add_indicator': False,\n",
       " 'knnimputer__copy': True,\n",
       " 'knnimputer__keep_empty_features': False,\n",
       " 'knnimputer__metric': 'nan_euclidean',\n",
       " 'knnimputer__missing_values': nan,\n",
       " 'knnimputer__n_neighbors': 5,\n",
       " 'knnimputer__weights': 'uniform',\n",
       " 'sgdclassifier__alpha': 0.0001,\n",
       " 'sgdclassifier__average': False,\n",
       " 'sgdclassifier__class_weight': None,\n",
       " 'sgdclassifier__early_stopping': False,\n",
       " 'sgdclassifier__epsilon': 0.1,\n",
       " 'sgdclassifier__eta0': 0.0,\n",
       " 'sgdclassifier__fit_intercept': True,\n",
       " 'sgdclassifier__l1_ratio': 0.15,\n",
       " 'sgdclassifier__learning_rate': 'optimal',\n",
       " 'sgdclassifier__loss': 'hinge',\n",
       " 'sgdclassifier__max_iter': 1000,\n",
       " 'sgdclassifier__n_iter_no_change': 5,\n",
       " 'sgdclassifier__n_jobs': None,\n",
       " 'sgdclassifier__penalty': 'l2',\n",
       " 'sgdclassifier__power_t': 0.5,\n",
       " 'sgdclassifier__random_state': None,\n",
       " 'sgdclassifier__shuffle': True,\n",
       " 'sgdclassifier__tol': 0.001,\n",
       " 'sgdclassifier__validation_fraction': 0.1,\n",
       " 'sgdclassifier__verbose': 0,\n",
       " 'sgdclassifier__warm_start': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "#print(titanic.shape)\n",
    "\n",
    "y = titanic[\"survived\"]\n",
    "X = titanic[[\"pclass\", \"age\"]]\n",
    "\n",
    "# random_state permet d'avoir toujours les 2 mêmes jeux\n",
    "# test_size permet de faire 80-20%\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=.2, random_state=0 )\n",
    "\n",
    "# SGDClassifier = Linear classifiers (SVM, logistic regression, etc.) with SGD training.\n",
    "model = make_pipeline(KNNImputer(), SGDClassifier())\n",
    "model.get_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par rapport à une fonction pandas pour faire de l'imputation, KNNImputer permet d'utiliser le Transformer avec GridSearchCV() afin d'en optimiser les caractéristiques\n",
    "\n",
    "Utiliser la sortie de model.get_params() pour trouver les noms des paramètres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knnimputer__n_neighbors': 3}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "  \"knnimputer__n_neighbors\" : [1, 2, 3, 4]\n",
    "  # on pourrait ajouter un paramètre de sgdclassifier__xxx à optimiser\n",
    "}\n",
    "\n",
    "grid = GridSearchCV (model, param_grid=params, cv=5)\n",
    "\n",
    "# on entraine la grid\n",
    "grid.fit(X_train, y_train) \n",
    "\n",
    "# affiche le nombre optimal de voisins à utiliser\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc ici, le nombre optimal de voisins à utiliser c'est 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3., 21.],\n",
       "       [ 2., 31.],\n",
       "       [ 2., 31.],\n",
       "       ...,\n",
       "       [ 3., 21.],\n",
       "       [ 3., 36.],\n",
       "       [ 2., 60.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=3)\n",
    "imputer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7039106145251397"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(KNNImputer(n_neighbors=3), SGDClassifier())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
